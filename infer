import argparse
import json
import os
import struct
from pathlib import Path

import numpy as np
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
from tqdm import tqdm
from dataset import MyTestDataset, save_emb

def get_ckpt_path():
    ckpt_path = os.environ.get("MODEL_OUTPUT_PATH")
    if ckpt_path is None: raise ValueError("MODEL_OUTPUT_PATH is not set")
    pt_files = [os.path.join(ckpt_path, f) for f in os.listdir(ckpt_path) if f.endswith(".pt")]
    if not pt_files:
        for sub in os.listdir(ckpt_path):
            subdir = os.path.join(ckpt_path, sub)
            if os.path.isdir(subdir):
                cand = os.path.join(subdir, "model.pt")
                if os.path.exists(cand):
                    pt_files.append(cand)
                    break
    if not pt_files: raise FileNotFoundError(f"No .pt checkpoint found under {ckpt_path}")
    return pt_files[0]
    
def get_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--batch_size', default=256, type=int)
    parser.add_argument('--lr', default=0.002, type=float)
    parser.add_argument('--maxlen', default=101, type=int)
    parser.add_argument('--hidden_units', default=128, type=int)
    parser.add_argument('--num_blocks', default=8, type=int)
    parser.add_argument('--num_epochs', default=7, type=int)
    parser.add_argument('--num_heads', default=8, type=int)
    parser.add_argument('--dropout_rate', default=0.2, type=float)
    parser.add_argument('--l2_emb', default=0.0, type=float)
    parser.add_argument('--device', default='cuda', type=str)
    parser.add_argument('--inference_only', action='store_true')
    parser.add_argument('--state_dict_path', default=None, type=str)
    parser.add_argument('--norm_first', action='store_true')
    parser.add_argument('--mm_emb_id', nargs='+', default=['81'], type=str, choices=[str(s) for s in range(81, 87)])
    parser.add_argument('--feat_session_gap', default=1800, type=int)

    args = parser.parse_args()
    return args

def read_result_ids(file_path):
    with open(file_path, 'rb') as f:
        num_points_query = struct.unpack('I', f.read(4))[0]
        query_ann_top_k = struct.unpack('I', f.read(4))[0]
        print(f"num_points_query: {num_points_query}, query_ann_top_k: {query_ann_top_k}")
        num_result_ids = num_points_query * query_ann_top_k
        result_ids = np.fromfile(f, dtype=np.uint64, count=num_result_ids)
        return result_ids.reshape((num_points_query, query_ann_top_k))

def process_cold_start_feat(feat):
    processed_feat = {}
    for feat_id, feat_value in feat.items():
        if isinstance(feat_value, list):
            value_list = [0 if isinstance(v, str) else v for v in feat_value]
            processed_feat[feat_id] = value_list
        elif isinstance(feat_value, str):
            processed_feat[feat_id] = 0
        else:
            processed_feat[feat_id] = feat_value
    return processed_feat

def renorm_fbin(fbin_path: Path):
    with open(fbin_path, 'rb') as f:
        n = struct.unpack('I', f.read(4))[0]
        d = struct.unpack('I', f.read(4))[0]
        vecs = np.fromfile(f, dtype=np.float32, count=n * d).reshape(n, d)
    norms = np.linalg.norm(vecs, axis=1, keepdims=True)
    vecs = vecs / np.clip(norms, 1e-12, None)
    with open(fbin_path, 'wb') as f:
        f.write(struct.pack('II', n, d))
        vecs.astype(np.float32).tofile(f)

def get_candidate_emb(indexer, feat_types, feat_default_value, mm_emb_dict, model, dataset):
    EMB_SHAPE_DICT = {"81": 32, "82": 1024, "83": 3584, "84": 4096, "85": 3584, "86": 3584}
    candidate_path = Path(os.environ.get('EVAL_DATA_PATH'), 'predict_set.jsonl')
    item_ids, creative_ids, retrieval_ids, features = [], [], [], []
    retrieve_id2creative_id = {}

    with open(candidate_path, 'r') as f:
        for line in f:
            line = json.loads(line)
            feature = line['features']
            creative_id = line['creative_id']
            retrieval_id = line['retrieval_id']
            item_id = indexer[creative_id] if creative_id in indexer else 0

            missing_fields = set(
                feat_types['item_sparse'] + feat_types['item_array'] + feat_types['item_continual']
            ) - set(feature.keys())

            feature = process_cold_start_feat(feature)
            for feat_id in missing_fields:
                feature[feat_id] = feat_default_value[feat_id]
            for feat_id in feat_types['item_emb']:
                if creative_id in mm_emb_dict[feat_id]:
                    feature[feat_id] = mm_emb_dict[feat_id][creative_id]
                else:
                    feature[feat_id] = np.zeros(EMB_SHAPE_DICT[feat_id], dtype=np.float32)
            
            i_key = dataset.indexer_i_rev.get(item_id, str(item_id))
            i_stat = dataset.i_stats.get(i_key, {'clk': 0, 'imp': 0})
            i_alpha, i_beta = dataset.bayes_params['i']
            i_static_ctr = dataset.get_smoothed_ctr(i_stat['clk'], i_stat['imp'], i_alpha, i_beta)
            feature['i_smooth_ctr'] = float(i_static_ctr)

            item_ids.append(item_id)
            creative_ids.append(creative_id)
            retrieval_ids.append(retrieval_id)
            features.append(feature)
            retrieve_id2creative_id[retrieval_id] = creative_id

    out_dir = Path(os.environ.get('EVAL_RESULT_PATH'))
    model.save_item_emb(item_ids, retrieval_ids, features, os.environ.get('EVAL_RESULT_PATH'))
    renorm_fbin(out_dir / 'embedding.fbin')

    with open(out_dir / "retrive_id2creative_id.json", "w") as f:
        json.dump(retrieve_id2creative_id, f)

    return retrieve_id2creative_id

def infer():
    args = get_args()
    data_path = os.environ.get('EVAL_DATA_PATH')

    test_dataset = MyTestDataset(data_path, args)
    test_loader = DataLoader(
        test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0, collate_fn=test_dataset.collate_fn
    )

    usernum, itemnum = test_dataset.usernum, test_dataset.itemnum
    feat_statistics, feat_types = test_dataset.feat_statistics, test_dataset.feature_types

    from model import BaselineModel
    model = BaselineModel(usernum, itemnum, feat_statistics, feat_types, args).to(args.device)

    ckpt_path = get_ckpt_path()
    state = torch.load(ckpt_path, map_location=torch.device(args.device))
    model.load_state_dict(state)
    model.eval()

    all_embs = []
    user_list = []

    with torch.no_grad():
        for step, batch in tqdm(enumerate(test_loader), total=len(test_loader)):
            seq, token_type, seq_feat, user_id = batch
            seq = seq.to(args.device)
            logits = model.predict(seq, seq_feat, token_type)
            logits = F.normalize(logits, p=2, dim=-1, eps=1e-12)
            all_embs.append(logits.detach().cpu().numpy().astype(np.float32))
            user_list += user_id

    retrieve_id2creative_id = get_candidate_emb(
        test_dataset.indexer['i'],
        test_dataset.feature_types,
        test_dataset.feature_default_value,
        test_dataset.mm_emb_dict,
        model,
        test_dataset
    )

    all_embs = np.concatenate(all_embs, axis=0)
    save_emb(all_embs, Path(os.environ.get('EVAL_RESULT_PATH'), 'query.fbin'))

    ann_cmd = (
        str(Path("/workspace", "faiss-based-ann", "faiss_demo"))
        + " --dataset_vector_file_path=" + str(Path(os.environ.get("EVAL_RESULT_PATH"), "embedding.fbin"))
        + " --dataset_id_file_path=" + str(Path(os.environ.get("EVAL_RESULT_PATH"), "id.u64bin"))
        + " --query_vector_file_path=" + str(Path(os.environ.get("EVAL_RESULT_PATH"), "query.fbin"))
        + " --result_id_file_path=" + str(Path(os.environ.get("EVAL_RESULT_PATH"), "id100.u64bin"))
        + " --query_ann_top_k=10 --faiss_M=64 --faiss_ef_construction=1280 --query_ef_search=640 --faiss_metric_type=0"
    )
    os.system(ann_cmd)

    top10s_retrieved = read_result_ids(Path(os.environ.get("EVAL_RESULT_PATH"), "id100.u64bin"))
    top10s_untrimmed = []
    for top10 in tqdm(top10s_retrieved):
        for item in top10:
            top10s_untrimmed.append(retrieve_id2creative_id.get(int(item), 0))

    top10s = [top10s_untrimmed[i:i + 10] for i in range(0, len(top10s_untrimmed), 10)]
    return top10s, user_list
